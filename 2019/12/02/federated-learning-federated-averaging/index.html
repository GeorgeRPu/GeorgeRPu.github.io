<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    
    
    <title>Federated Learning: Federated Averaging (Part 1)</title>
    <meta name="description" content="Introduction In recent years, there has been political and consumer backlash against the constant surveillance of tech companies. In response, companies have turned to federated learning, a technique which enables the training of a single model from decentralized data. Imagine we have $K$ numbered clients. Clients perform the bulk of the computation. Each client $1 \leq k \leq K$ has its own dataset $D_k$, a local model $f_k$, and a loss function $L_k$. Generally, the local loss functions are sums over the client’s dataset. \[L_k = \sum_{i \in D_k} \ell(f_\theta(x_i), y_i)\] Here $\ell(\hat{y}, y)$ is the per-example loss; it measures the difference between the label $y$ and the prediction $\hat{y}$. A server coordinates the learning process; it usually has no data of its own. The goal is to train a global model $f$ which minimizes the total loss $L = \sum_{k=1}^{K} L_k$. For now, we assume all models have the same architecture but different parameters. Lets look at some possible applications of federated learning. Word completion[1]. Smartphone keyboards attempt to autocomplete words based on the characters typed. Each Android phone has its own record of typed characters and the finished word. Because pooling data from millions of phones is invasive and expensive, Google uses federated learning to learn a universal word prediction model. Illness prediction. Hospitals are required by law to keep patient information private. However, a group of small hospitals want to use their collective data to train a neural network which can guess ailments based on symptoms. The hospitals decide to use federated learning to learn a collective model without sharing sensitive data. Graphic from [1] Federated SGD So federated learning appears to be quite useful. But how exactly do we train a global model without having access to training data? Let’s consider the typical training loop in supervised learning. for e in range(EPOCHS): for x, y in dataset: # x, y can be mini-batches loss = loss_function(model(x), y) grad = compute_gradient(loss) update_params(grad) Recall that the total loss function $L$ is the sum of many different loss functions $L_k$. Taking the gradient wrt $\theta$ yields \[\nabla L(\theta) = \sum_{i=1}^{K} \nabla L_k({\theta}).\] Each client only has enough data to compute $\nabla L_k({\theta})$. However, by having the server add these together, we can know $\nabla L(\theta)$. Thus FedSGD has each client—more often a randomly chosen subset of all clients—compute its local gradient $\nabla L_k({\theta})$ which are sent to the server for aggregation. The server updates the parameters which are broadcasted to the clients. for c in range(COMM_ROUNDS): for client in clients: # do in parallel for x, y in client.dataset: # x, y can be mini-batches loss = loss_function(client.model(x), y) grad = compute_gradient(loss) total_grad = server.aggregate_gradients(clients) server.update_params(total_grad) server.broadcast_params(clients) Federated Averaging The problem with FedSGD is the communication cost. Imagine training a neural network to recognize handwritten digits using the MNIST dataset, which has 60,000 training examples. This should only take about 20 epochs—passes through the dataset. With a batch size of 100, there are $60,!000/100 \cdot 20 = 12,!000$ updates. In FedSGD, each update would require an onerous process of clients computing and sending gradients, aggregation, then the server broadcasting parameters. This is bad, especially considering the ever increasing size of models. A little bit of math reveals that there might be a solution. Suppose the server uses Stochastic Gradient Descent to update the weights. Let $\eta$ be the learning rate. \[\theta \gets \theta - \eta \nabla L(\theta)\] Replace $\nabla L(\theta)$ with $\sum_{k=1}^{K} \nabla L_k(\theta)$. \[\theta \gets \theta - \eta \sum_{k=1}^{K} \frac{n_k}{n} \nabla L_k(\theta)\] Notice that $\theta$ can be moved inside the sum. \[\theta \gets \sum_{k=1}^{K} \left(\frac{\theta}{K} - \eta \nabla L_k(\theta)\right)\] Having the server update the parameters using the aggregated gradient is equivalent to the clients perform the update, then “averaging” the parameters on the server later. If the clients can perform multiple updates, then the server will need to average less frequently, reducing communication costs. for t in range(COMM_ROUNDS): for client in clients: # do in parallel for i in range(EPOCHS): for x, y in client.dataset: # x, y are mini-batches loss = loss_function(client.model(x), y) grad = compute_gradient(loss) client.update_params(grad) server.average_params(clients) server.broadcast_params(clients) Convex Loss Functions? However, neural network loss functions are non-convex in general. So there is no guarantee that averaging (the parameters of) multiple models produces a better model. \[L\left(\frac{1}{K} \sum_{k=1}^{K} \theta_k\right) \not\leq L(\theta_j) \qquad 0 \leq j \leq K\] Training 2 neural networks from different initialized parameters demonstrates this. The averaged parameters do worse than before. However, this is not the case when training 2 neural networks from the same initialization. In fact, plotting the loss resulting from different weighted averages of the parameters reveals a nice U-shaped graph. Figure 1 from [2] Limitations FedAvg works well when the client datasets are IID—identically and independently—distributed [2]. (Note that the accuracy figures are made monotonic. If $a_1, a_2, \dots$ are the actual accuracies, then the plotted value at time $t$ is $\max_{s \leq t}(a_s)$.) Returning to the Illness Prediction example, the hospital’s dataset would be IID if all contained the same types of diagnoses. So hospital A’s dataset cannot consist of mostly flu examples while hospital B has low amounts of flu cases. However, when data is non-IID, it’s performance suffers. In particular, actual accuracy can vary wildly between communication rounds. Another issue is the number of hyperparameters to manage. There is the proportion of clients which participate each round $C$, the number of epochs $E$, and the batch size $B$. While moderate values of each do fine ($C \approx 0.1, E \approx 5, B \approx 10$), there is a complex interplay between them. Figure 3 from [2] Lastly, before averaging, the server must wait for every client to finish $E$ epochs. As clients may have different amounts of hardware, faster clients are now idle while the server waits for slower clients. We might try to amend this by fixing a timed interval during which each client performs local updates. But now the averages are biased—especially in the beginning of training—towards the faster clients. The averaged model will perform better on some datasets than others. Training is uneven. References http://ai.googleblog.com/2017/04/federated-learning-collaborative.html. Brendan McMahan, Daniel Ramage. Communication-Efficient Learning of Deep Networks from Decentralized Data. H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, Blaise Agüera y Arcas. Federated Learning: Challenges, Methods, and Future Directions. Tian Li, Anit Kumar Sahu, Ameet Talwalkar, Virginia Smith.">
    

    <link rel="stylesheet" href="/assets/main.css">
    <link rel="canonical" href="https://georgerpu.github.io/2019/12/02/federated-learning-federated-averaging/">
    
    
    <link rel="alternate" type="application/rss+xml" title="George Pu" href="https://georgerpu.github.io/feed.xml">

    

    
    <meta property="og:title" content="Federated Learning: Federated Averaging (Part 1)">
    <meta property="og:site_name" content="George Pu">
    <meta property="og:url" content="https://georgerpu.github.io/2019/12/02/federated-learning-federated-averaging/">
    <meta property="og:description" content="Introduction In recent years, there has been political and consumer backlash against the constant surveillance of tech companies. In response, companies have turned to federated learning, a technique which enables the training of a single model from decentralized data. Imagine we have $K$ numbered clients. Clients perform the bulk of the computation. Each client $1 \leq k \leq K$ has its own dataset $D_k$, a local model $f_k$, and a loss function $L_k$. Generally, the local loss functions are sums over the client’s dataset. \[L_k = \sum_{i \in D_k} \ell(f_\theta(x_i), y_i)\] Here $\ell(\hat{y}, y)$ is the per-example loss; it measures the difference between the label $y$ and the prediction $\hat{y}$. A server coordinates the learning process; it usually has no data of its own. The goal is to train a global model $f$ which minimizes the total loss $L = \sum_{k=1}^{K} L_k$. For now, we assume all models have the same architecture but different parameters. Lets look at some possible applications of federated learning. Word completion[1]. Smartphone keyboards attempt to autocomplete words based on the characters typed. Each Android phone has its own record of typed characters and the finished word. Because pooling data from millions of phones is invasive and expensive, Google uses federated learning to learn a universal word prediction model. Illness prediction. Hospitals are required by law to keep patient information private. However, a group of small hospitals want to use their collective data to train a neural network which can guess ailments based on symptoms. The hospitals decide to use federated learning to learn a collective model without sharing sensitive data. Graphic from [1] Federated SGD So federated learning appears to be quite useful. But how exactly do we train a global model without having access to training data? Let’s consider the typical training loop in supervised learning. for e in range(EPOCHS): for x, y in dataset: # x, y can be mini-batches loss = loss_function(model(x), y) grad = compute_gradient(loss) update_params(grad) Recall that the total loss function $L$ is the sum of many different loss functions $L_k$. Taking the gradient wrt $\theta$ yields \[\nabla L(\theta) = \sum_{i=1}^{K} \nabla L_k({\theta}).\] Each client only has enough data to compute $\nabla L_k({\theta})$. However, by having the server add these together, we can know $\nabla L(\theta)$. Thus FedSGD has each client—more often a randomly chosen subset of all clients—compute its local gradient $\nabla L_k({\theta})$ which are sent to the server for aggregation. The server updates the parameters which are broadcasted to the clients. for c in range(COMM_ROUNDS): for client in clients: # do in parallel for x, y in client.dataset: # x, y can be mini-batches loss = loss_function(client.model(x), y) grad = compute_gradient(loss) total_grad = server.aggregate_gradients(clients) server.update_params(total_grad) server.broadcast_params(clients) Federated Averaging The problem with FedSGD is the communication cost. Imagine training a neural network to recognize handwritten digits using the MNIST dataset, which has 60,000 training examples. This should only take about 20 epochs—passes through the dataset. With a batch size of 100, there are $60,!000/100 \cdot 20 = 12,!000$ updates. In FedSGD, each update would require an onerous process of clients computing and sending gradients, aggregation, then the server broadcasting parameters. This is bad, especially considering the ever increasing size of models. A little bit of math reveals that there might be a solution. Suppose the server uses Stochastic Gradient Descent to update the weights. Let $\eta$ be the learning rate. \[\theta \gets \theta - \eta \nabla L(\theta)\] Replace $\nabla L(\theta)$ with $\sum_{k=1}^{K} \nabla L_k(\theta)$. \[\theta \gets \theta - \eta \sum_{k=1}^{K} \frac{n_k}{n} \nabla L_k(\theta)\] Notice that $\theta$ can be moved inside the sum. \[\theta \gets \sum_{k=1}^{K} \left(\frac{\theta}{K} - \eta \nabla L_k(\theta)\right)\] Having the server update the parameters using the aggregated gradient is equivalent to the clients perform the update, then “averaging” the parameters on the server later. If the clients can perform multiple updates, then the server will need to average less frequently, reducing communication costs. for t in range(COMM_ROUNDS): for client in clients: # do in parallel for i in range(EPOCHS): for x, y in client.dataset: # x, y are mini-batches loss = loss_function(client.model(x), y) grad = compute_gradient(loss) client.update_params(grad) server.average_params(clients) server.broadcast_params(clients) Convex Loss Functions? However, neural network loss functions are non-convex in general. So there is no guarantee that averaging (the parameters of) multiple models produces a better model. \[L\left(\frac{1}{K} \sum_{k=1}^{K} \theta_k\right) \not\leq L(\theta_j) \qquad 0 \leq j \leq K\] Training 2 neural networks from different initialized parameters demonstrates this. The averaged parameters do worse than before. However, this is not the case when training 2 neural networks from the same initialization. In fact, plotting the loss resulting from different weighted averages of the parameters reveals a nice U-shaped graph. Figure 1 from [2] Limitations FedAvg works well when the client datasets are IID—identically and independently—distributed [2]. (Note that the accuracy figures are made monotonic. If $a_1, a_2, \dots$ are the actual accuracies, then the plotted value at time $t$ is $\max_{s \leq t}(a_s)$.) Returning to the Illness Prediction example, the hospital’s dataset would be IID if all contained the same types of diagnoses. So hospital A’s dataset cannot consist of mostly flu examples while hospital B has low amounts of flu cases. However, when data is non-IID, it’s performance suffers. In particular, actual accuracy can vary wildly between communication rounds. Another issue is the number of hyperparameters to manage. There is the proportion of clients which participate each round $C$, the number of epochs $E$, and the batch size $B$. While moderate values of each do fine ($C \approx 0.1, E \approx 5, B \approx 10$), there is a complex interplay between them. Figure 3 from [2] Lastly, before averaging, the server must wait for every client to finish $E$ epochs. As clients may have different amounts of hardware, faster clients are now idle while the server waits for slower clients. We might try to amend this by fixing a timed interval during which each client performs local updates. But now the averages are biased—especially in the beginning of training—towards the faster clients. The averaged model will perform better on some datasets than others. Training is uneven. References http://ai.googleblog.com/2017/04/federated-learning-collaborative.html. Brendan McMahan, Daniel Ramage. Communication-Efficient Learning of Deep Networks from Decentralized Data. H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, Blaise Agüera y Arcas. Federated Learning: Challenges, Methods, and Future Directions. Tian Li, Anit Kumar Sahu, Ameet Talwalkar, Virginia Smith.">
    
    
    <meta name="twitter:card" content="summary">
    
    <meta name="twitter:title" content="Federated Learning: Federated Averaging (Part 1)">
    <meta name="twitter:description" content="Introduction In recent years, there has been political and consumer backlash against the constant surveillance of tech companies. In response, companies have turned to federated learning, a techniq...">
    
    

    <link rel="dns-prefetch" href="https://fonts.gstatic.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Bitter:ital,wght@0,400;0,700;1,400&amp;display=swap" rel="stylesheet">

    


    <!-- MathJax -->
    <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
       <script type="text/x-mathjax-config">
         MathJax.Hub.Config({
           tex2jax: {
             inlineMath: [ ['$','$'], ["\\(","\\)"] ],
             processEscapes: true
           }
         });
       </script>
       <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

       <!-- Mermaid -->
       <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js"></script>
  </head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">George Pu</a>

    <nav class="site-nav">
      
        
        <a class="page-link" href="/about/">About</a>
      
        
        <a class="page-link" href="/publications/">Publications</a>
      
        
        <a class="page-link" href="/teaching/">Teaching</a>
      
    </nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    
      <h1 class="post-title" itemprop="name headline">Federated Learning: Federated Averaging (Part 1)</h1>
    
    <p class="post-meta"><time datetime="2019-12-02T00:00:00+00:00" itemprop="datePublished">Dec 2, 2019</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <h2>Introduction</h2>

<p>In recent years, there has been political and consumer backlash against the constant surveillance of tech companies. In response, companies have turned to <a href="https://federated.withgoogle.com/"><strong>federated learning</strong></a>, a technique which enables the training of a single model from decentralized data. Imagine we have $K$ numbered <strong>clients</strong>. Clients perform the bulk of the computation. Each client $1 \leq k \leq K$ has its own dataset $D_k$, a local model $f_k$, and a loss function $L_k$.</p>

<p>Generally, the local loss functions are sums over the client’s dataset.</p>

\[L_k = \sum_{i \in D_k} \ell(f_\theta(x_i), y_i)\]

<p>Here $\ell(\hat{y}, y)$ is the per-example loss; it measures the difference between the label $y$ and the prediction $\hat{y}$. A <strong>server</strong> coordinates the learning process; it usually has no data of its own. The goal is to train a global model $f$ which minimizes the total loss $L = \sum_{k=1}^{K} L_k$. For now, we assume all models have the same architecture but different parameters.</p>

<p>Lets look at some possible applications of federated learning.</p>
<ul>
  <li><strong>Word completion</strong>[1]. Smartphone keyboards attempt to autocomplete words based on the characters typed. Each Android phone has its own record of typed characters and the finished word. Because pooling data from millions of phones is invasive and expensive, Google uses federated learning to learn a universal word prediction model.</li>
  <li><strong>Illness prediction</strong>. Hospitals are required by law to keep patient information private. However, a group of small hospitals want to use their collective data to train a neural network which can guess ailments based on symptoms. The hospitals decide to use federated learning to learn a collective model without sharing sensitive data.</li>
</ul>

<figure>
    <img src="https://georgerpu.github.io/assets/images/2019-12-02/federated-learning.png" alt="Federated learning flow chart" class="centerImage" />
    <figcaption>Graphic from [1]</figcaption>
</figure>

<h3>Federated SGD</h3>

<p>So federated learning appears to be quite useful. But how exactly do we train a global model without having access to training data? Let’s consider the typical training loop in supervised learning.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>   <span class="c1"># x, y can be mini-batches
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">compute_gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">update_params</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div></div>

<p>Recall that the total loss function $L$ is the sum of many different loss functions $L_k$. Taking the gradient wrt $\theta$ yields</p>

\[\nabla L(\theta) = \sum_{i=1}^{K} \nabla L_k({\theta}).\]

<p>Each client only has enough data to compute $\nabla L_k({\theta})$. However, by having the server add these together, we can know $\nabla L(\theta)$. Thus FedSGD has each client—more often a randomly chosen subset of all clients—compute its local gradient $\nabla L_k({\theta})$ which are sent to the server for aggregation. The server updates the parameters which are broadcasted to the clients.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">COMM_ROUNDS</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">client</span> <span class="ow">in</span> <span class="n">clients</span><span class="p">:</span>  <span class="c1"># do in parallel
</span>        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">client</span><span class="p">.</span><span class="n">dataset</span><span class="p">:</span>  <span class="c1"># x, y can be mini-batches
</span>            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">client</span><span class="p">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
        	<span class="n">grad</span> <span class="o">=</span> <span class="n">compute_gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

    <span class="n">total_grad</span> <span class="o">=</span> <span class="n">server</span><span class="p">.</span><span class="n">aggregate_gradients</span><span class="p">(</span><span class="n">clients</span><span class="p">)</span>
    <span class="n">server</span><span class="p">.</span><span class="n">update_params</span><span class="p">(</span><span class="n">total_grad</span><span class="p">)</span>
    <span class="n">server</span><span class="p">.</span><span class="n">broadcast_params</span><span class="p">(</span><span class="n">clients</span><span class="p">)</span>
</code></pre></div></div>

<h2>Federated Averaging</h2>

<p>The problem with FedSGD is the communication cost. Imagine training a neural network to recognize handwritten digits using the MNIST dataset, which has 60,000 training examples. This should only take about 20 epochs—passes through the dataset. With a batch size of 100, there are $60,!000/100 \cdot 20 = 12,!000$ updates. In FedSGD, each update would require an onerous process of clients computing and sending gradients, aggregation, then the server broadcasting parameters. This is bad, especially considering the ever increasing size of models.</p>

<p>A little bit of math reveals that there might be a solution. Suppose the server uses Stochastic Gradient Descent to update the weights. Let $\eta$ be the learning rate.</p>

\[\theta \gets \theta - \eta \nabla L(\theta)\]

<p>Replace $\nabla L(\theta)$ with $\sum_{k=1}^{K} \nabla L_k(\theta)$.</p>

\[\theta \gets \theta - \eta \sum_{k=1}^{K} \frac{n_k}{n} \nabla L_k(\theta)\]

<p>Notice that $\theta$ can be moved inside the sum.</p>

\[\theta \gets \sum_{k=1}^{K} \left(\frac{\theta}{K} - \eta \nabla L_k(\theta)\right)\]

<p>Having the server update the parameters using the aggregated gradient is equivalent to the clients perform the update, then “averaging” the parameters on the server later. If the clients can perform multiple updates, then the server will need to average less frequently, reducing  communication costs.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">COMM_ROUNDS</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">client</span> <span class="ow">in</span> <span class="n">clients</span><span class="p">:</span>  <span class="c1"># do in parallel
</span>    	<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">client</span><span class="p">.</span><span class="n">dataset</span><span class="p">:</span>  <span class="c1"># x, y are mini-batches
</span>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">client</span><span class="p">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
                <span class="n">grad</span> <span class="o">=</span> <span class="n">compute_gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
                <span class="n">client</span><span class="p">.</span><span class="n">update_params</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>

    <span class="n">server</span><span class="p">.</span><span class="n">average_params</span><span class="p">(</span><span class="n">clients</span><span class="p">)</span>
    <span class="n">server</span><span class="p">.</span><span class="n">broadcast_params</span><span class="p">(</span><span class="n">clients</span><span class="p">)</span>
</code></pre></div></div>

<h3>Convex Loss Functions?</h3>

<p>However, neural network loss functions are non-convex in general. So there is no guarantee that averaging (the parameters of) multiple models produces a better model.</p>

\[L\left(\frac{1}{K} \sum_{k=1}^{K} \theta_k\right) \not\leq L(\theta_j) \qquad 0 \leq j \leq K\]

<p>Training 2 neural networks from <em>different</em> initialized parameters demonstrates this. The averaged parameters do worse than before. However, this is not the case when training 2 neural networks from the <em>same</em> initialization. In fact, plotting the loss resulting from different weighted averages of the parameters reveals a nice U-shaped graph.</p>

<figure>
    <img src="https://georgerpu.github.io/assets/images/2019-12-02/convex-loss.png" alt="Convex loss when same init" class="centerImage" />
    <figcaption>Figure 1 from [2]</figcaption>
</figure>

<h2>Limitations</h2>

<p>FedAvg works well when the client datasets are IID—identically and independently—distributed [2]. (Note that the accuracy figures are made monotonic. If $a_1, a_2, \dots$ are the actual accuracies, then the plotted value at time $t$ is $\max_{s \leq t}(a_s)$.) Returning to the Illness Prediction example, the hospital’s dataset would be IID if all contained the same types of diagnoses. So hospital A’s dataset cannot consist of mostly flu examples while hospital B has low amounts of flu cases. However, when data is non-IID, it’s performance suffers. In particular, actual accuracy can vary wildly between communication rounds.</p>

<p>Another issue is the number of hyperparameters to manage. There is the proportion of clients which participate each round $C$, the number of epochs $E$, and the batch size $B$. While moderate values of each do fine ($C \approx 0.1, E \approx 5, B \approx 10$), there is a complex interplay between them.</p>

<figure>
    <img src="https://georgerpu.github.io/assets/images/2019-12-02/loss-comm-round.png" alt="Loss comm round curves" class="centerImage" />
    <figcaption>Figure 3 from [2]</figcaption>
</figure>

<p>Lastly, before averaging, the server must wait for every client to finish $E$ epochs. As clients may have different amounts of hardware, faster clients are now idle while the server waits for slower clients. We might try to amend this by fixing a timed interval during which each client performs local updates. But now the averages are biased—especially in the beginning of training—towards the faster clients. The averaged model will perform better on some datasets than others. Training is uneven.</p>

<h2>References</h2>

<ol>
  <li><a href="http://ai.googleblog.com/2017/04/federated-learning-collaborative.html">http://ai.googleblog.com/2017/04/federated-learning-collaborative.html</a>. Brendan McMahan, Daniel Ramage.</li>
  <li><a href="https://arxiv.org/abs/1602.05629">Communication-Efficient Learning of Deep Networks from Decentralized Data</a>. H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, Blaise Agüera y Arcas.</li>
  <li><a href="https://arxiv.org/abs/1908.07873">Federated Learning: Challenges, Methods, and Future Directions</a>. Tian Li, Anit Kumar Sahu, Ameet Talwalkar, Virginia Smith.</li>
</ol>

  </div>

  

</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <p>
      

&copy; George Pu - Powered by <a href="https://jekyllrb.com">Jekyll</a> &amp; <a href="https://github.com/yous/whiteglass">whiteglass</a> - Subscribe via <a href="https://georgerpu.github.io/feed.xml">RSS</a>

    </p>

  </div>

</footer>


  </body>

</html>
